{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Selvaria\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# !/usr/bin/python\n",
    "# Author: Selvaria\n",
    "\n",
    "# 模型构建和设计\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=49, shape=(2, 20), dtype=float32, numpy=\n",
       "array([[3.6156774e-02, 1.4954937e-01, 3.4812140e-01, 4.6542645e-01,\n",
       "        2.2801602e-01, 2.5271642e-01, 1.3856304e-01, 7.2027147e-01,\n",
       "        9.6304202e-01, 5.4294157e-01, 2.2437203e-01, 7.1472394e-01,\n",
       "        3.9470804e-01, 9.1624260e-04, 3.8572931e-01, 9.5799685e-01,\n",
       "        1.2486267e-01, 2.7660322e-01, 7.2270083e-01, 3.4564829e-01],\n",
       "       [7.9393077e-01, 5.1483917e-01, 5.7949400e-01, 3.1905949e-01,\n",
       "        6.4718223e-01, 2.4003196e-01, 7.6118279e-01, 2.1996057e-01,\n",
       "        7.2862136e-01, 9.1994321e-01, 5.1285851e-01, 1.5239441e-01,\n",
       "        6.2276721e-01, 5.4478800e-01, 4.5891428e-01, 8.5810685e-01,\n",
       "        2.8366303e-01, 5.6518555e-01, 8.6875117e-01, 5.0242186e-02]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((2,20)) \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=62, shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.14354907,  0.05338682, -0.40425608, -0.2587788 , -0.08983592,\n",
       "         0.24334475,  0.08793818, -0.5242768 , -0.06720618,  0.17471312],\n",
       "       [-0.01480664,  0.16989782, -0.4945268 , -0.17466378,  0.14202915,\n",
       "        -0.02115927, -0.0175516 , -0.611707  , -0.027931  ,  0.10718849]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义MLP模型结构\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         \n",
    "        x = self.flatten(inputs)   \n",
    "        x = self.dense1(x)    \n",
    "        output = self.dense2(x)     \n",
    "        return output\n",
    "    \n",
    "X = tf.random.uniform((2,20)) \n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=117, shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.0521878 ,  0.0668958 , -0.06255163,  0.03062708, -0.14593492,\n",
       "         0.10147388, -0.04072712, -0.11214042, -0.02359716, -0.13605078],\n",
       "       [-0.2278136 , -0.04991286,  0.08795225,  0.17137462, -0.02623325,\n",
       "         0.07074243, -0.05856334, -0.07146536,  0.12810664, -0.07756173]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正常的keras实现：也可以用add函数\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更灵活一些\n",
    "\n",
    "class FancyMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.rand_weight = tf.constant(\n",
    "            tf.random.uniform((20,20)))\n",
    "        self.dense = tf.keras.layers.Dense(units=20, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs):         \n",
    "        x = self.flatten(inputs)   \n",
    "        x = tf.nn.relu(tf.matmul(x, self.rand_weight) + 1)\n",
    "        x = self.dense(x)    \n",
    "        while tf.norm(x) > 1:\n",
    "            x /= 2\n",
    "        if tf.norm(x) < 0.8:\n",
    "            x *= 10\n",
    "        return tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=311, shape=(), dtype=float32, numpy=23.746525>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义后可直接通过add函数调用\n",
    "\n",
    "class NestMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = tf.keras.Sequential()\n",
    "        self.net.add(tf.keras.layers.Flatten())\n",
    "        self.net.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "        self.net.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "        self.dense = tf.keras.layers.Dense(units=16, activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "    def call(self, inputs):         \n",
    "        return self.dense(self.net(inputs))\n",
    "\n",
    "net = tf.keras.Sequential()\n",
    "net.add(NestMLP())\n",
    "net.add(tf.keras.layers.Dense(20))\n",
    "net.add(FancyMLP())\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.02536002,  0.21001825,  0.2942347 ,  0.37226382, -0.27594352,\n",
       "        -0.1072491 , -0.01887954, -0.16058698, -0.0123478 ,  0.0620673 ],\n",
       "       [-0.00090306,  0.30016986,  0.2668451 ,  0.20013687, -0.45570928,\n",
       "        -0.09548484, -0.31233752, -0.21917205,  0.00874135,  0.05590382]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型的权重\n",
    "\n",
    "net = tf.keras.models.Sequential()\n",
    "net.add(tf.keras.layers.Flatten())\n",
    "net.add(tf.keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "net.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "X = tf.random.uniform((2,20))\n",
    "Y = net(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'sequential/dense/kernel:0' shape=(20, 256) dtype=float32, numpy=\n",
       " array([[ 0.04821877,  0.01971839, -0.1322133 , ..., -0.02457005,\n",
       "         -0.0513386 , -0.04596808],\n",
       "        [-0.08145669,  0.10399023,  0.00986847, ...,  0.09806436,\n",
       "         -0.08687238,  0.09704998],\n",
       "        [ 0.00680166,  0.14200485,  0.11452475, ..., -0.00169985,\n",
       "          0.03269209,  0.07975852],\n",
       "        ...,\n",
       "        [ 0.14109606,  0.10782537, -0.04107142, ...,  0.08147974,\n",
       "          0.08208396,  0.02260047],\n",
       "        [-0.08611073,  0.12286136,  0.01139548, ...,  0.13120255,\n",
       "          0.10408655,  0.0368717 ],\n",
       "        [ 0.09235047, -0.03619536, -0.146383  , ..., -0.13490865,\n",
       "          0.09247346, -0.03999708]], dtype=float32)>,\n",
       " tensorflow.python.ops.resource_variable_ops.ResourceVariable)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0], type(net.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 设为均值为0、标准差为0.01的正态分布随机数(代码里似乎并非这样），并依然将偏差参数清零\n",
    "\n",
    "class Linear(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(\n",
    "            units=10,\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.zeros_initializer(), # tf.random_normal_initializer(mean=0.0, stddev=0.01)\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "        self.d2 = tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.ones_initializer(),\n",
    "            bias_initializer=tf.ones_initializer()\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.d1(input)\n",
    "        output = self.d2(x)\n",
    "        return output\n",
    "\n",
    "net = Linear()\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear/dense_2/kernel:0' shape=(20, 10) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Variable 'linear/dense_2/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'linear/dense_3/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)>,\n",
       " <tf.Variable 'linear/dense_3/bias:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential_2/dense_5/kernel:0' shape=(20, 64) dtype=float32, numpy=\n",
       " array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Variable 'sequential_2/dense_5/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义初始化，感觉没啥区别\n",
    "\n",
    "def my_init():\n",
    "    return tf.keras.initializers.Ones()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, kernel_initializer=my_init()))\n",
    "\n",
    "Y = model(X)\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(5,), dtype=int32, numpy=array([-2, -1,  0,  1,  2])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义层(layer)\n",
    "\n",
    "# 自定义了一个将输入减掉均值后输出的层，并将层的计算定义在了call函数里。这个层里不含模型参数\n",
    "class CenteredLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs - tf.reduce_mean(inputs)\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(2, 20), dtype=float32, numpy=\n",
       "array([[-0.09796398, -0.9546359 ,  0.8371567 ,  0.8377847 ,  0.13546357,\n",
       "         0.18864506, -0.2659811 , -0.12369398, -0.56885   ,  0.02776444,\n",
       "        -0.14654467, -0.24138471, -0.5922776 , -0.67358243, -0.5022928 ,\n",
       "         0.51680523,  0.07384016,  0.6827046 ,  0.4636204 ,  0.8489546 ],\n",
       "       [-0.037692  , -0.9103488 ,  1.1209129 ,  0.09312033, -0.47520128,\n",
       "         0.11904681, -0.36028138,  0.02276197, -0.7714759 ,  0.04662424,\n",
       "         0.10191447,  0.34162793, -0.3963228 , -0.41576925,  0.3425236 ,\n",
       "         0.14212367, -0.2709455 , -0.21559405,  0.11220275,  0.9652403 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接应用于模型的构建\n",
    "\n",
    "net = tf.keras.models.Sequential()\n",
    "net.add(tf.keras.layers.Flatten())\n",
    "net.add(tf.keras.layers.Dense(20))\n",
    "net.add(CenteredLayer())\n",
    "\n",
    "X = tf.random.uniform((2,20)) # \n",
    "Y = net(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units: 4\n",
      "input_shape: (2, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.01107107, -0.06184303,  0.02175089,  0.11343133],\n",
       "        [ 0.07814262, -0.04085029, -0.00610991,  0.03317473],\n",
       "        [-0.04373477,  0.0601783 ,  0.03261429,  0.10310387],\n",
       "        [ 0.04387454,  0.01911958, -0.00698581, -0.023418  ],\n",
       "        [-0.09526867,  0.03220423,  0.03135252,  0.01348117],\n",
       "        [ 0.05873218,  0.02445574,  0.05837744,  0.00269256],\n",
       "        [ 0.01526726, -0.00449585, -0.06728358,  0.02487175],\n",
       "        [-0.07703592,  0.00366705, -0.00213093,  0.00627941],\n",
       "        [ 0.07019436, -0.00303624,  0.01894838, -0.04115822],\n",
       "        [-0.01011225,  0.0024974 ,  0.03161853,  0.01224643],\n",
       "        [-0.08700826,  0.03375994, -0.02537072, -0.03417142],\n",
       "        [ 0.0036299 ,  0.08044641,  0.1015109 ,  0.11611362],\n",
       "        [ 0.05359798,  0.02131139, -0.0219804 , -0.07504892],\n",
       "        [-0.03139121,  0.03468395,  0.01180844, -0.05017263],\n",
       "        [ 0.03015341,  0.02195281,  0.01837931,  0.02318553],\n",
       "        [ 0.02733223,  0.0120684 , -0.0793448 , -0.01146867],\n",
       "        [ 0.02668274, -0.02179747,  0.00369689,  0.03505336],\n",
       "        [ 0.11036315,  0.08483217,  0.07269281, -0.01352465],\n",
       "        [ 0.01572947,  0.05648938, -0.04724335, -0.08334564],\n",
       "        [ 0.06397667,  0.0493535 , -0.0346388 , -0.01462372]],\n",
       "       dtype=float32), array([0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义含模型参数的自定义层。其中的模型参数可以通过训练学出\n",
    "\n",
    "# 自定义实现全连接层的计算\n",
    "class myDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):     # 这里 input_shape 是第一次运行call()时参数inputs的形状\n",
    "        print('units:',self.units) # 这是输出单元个数\n",
    "        print('input_shape:',input_shape) #\n",
    "        self.w = self.add_weight(name='w',\n",
    "            shape=[input_shape[-1], self.units], initializer=tf.random_normal_initializer())\n",
    "        self.b = self.add_weight(name='b',\n",
    "            shape=[self.units], initializer=tf.zeros_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "dense = myDense(4)\n",
    "dense(X)\n",
    "dense.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units: 8\n",
      "input_shape: (2, 20)\n",
      "units: 1\n",
      "input_shape: (2, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-0.00804436],\n",
       "       [-0.01073209]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential()\n",
    "net.add(myDense(8))\n",
    "net.add(myDense(1))\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
