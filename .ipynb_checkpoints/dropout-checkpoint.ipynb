{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Selvaria\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 8), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# !/usr/bin/python\n",
    "# Author: Selvaria\n",
    "\n",
    "# 丢弃法（dropout）\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras, nn, losses\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "def dropout(X, drop_prob):\n",
    "    assert 0 <= drop_prob <= 1\n",
    "    keep_prob = 1 - drop_prob\n",
    "    # 这种情况下把全部元素都丢弃\n",
    "    if keep_prob == 0:\n",
    "        return tf.zeros_like(X)\n",
    "    #初始mask为一个bool型数组，故需要强制类型转换\n",
    "    mask = tf.random.uniform(shape=X.shape, minval=0, maxval=1) < keep_prob # 这部分应该是tf矩阵的特殊用法，见下个cell\n",
    "    \n",
    "    # 为了保证层的期望不变，所以要在mask与dropout矩阵乘积后，要除以1-p（p是drop_prob），即扩大1/1-p倍\n",
    "    return tf.cast(mask, dtype=tf.float32) * tf.cast(X, dtype=tf.float32) / keep_prob\n",
    "\n",
    "X = tf.reshape(tf.range(0, 16), shape=(2, 8))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33, shape=(2, 8), dtype=float32, numpy=\n",
       "array([[ 0.,  0.,  0.,  6.,  8., 10., 12.,  0.],\n",
       "       [16.,  0.,  0.,  0.,  0., 26., 28.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: \n",
      " tf.Tensor(\n",
      "[[0.22331715 0.5059141  0.8572267  0.8425344  0.6099726  0.82404006\n",
      "  0.18501437 0.9670203 ]\n",
      " [0.61566174 0.509531   0.5508919  0.18257594 0.15230393 0.48221183\n",
      "  0.29999864 0.12934387]], shape=(2, 8), dtype=float32)\n",
      "check: \n",
      " tf.Tensor(\n",
      "[[ True False False False False False  True False]\n",
      " [False False False  True  True  True  True  True]], shape=(2, 8), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "mask = tf.random.uniform(shape=X.shape, minval=0, maxval=1)\n",
    "print('mask: \\n',mask)\n",
    "mask_check = mask < 0.5\n",
    "print('check: \\n',mask_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "\n",
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal(stddev=0.01, shape=(num_inputs, num_hiddens1)))\n",
    "b1 = tf.Variable(tf.zeros(num_hiddens1))\n",
    "W2 = tf.Variable(tf.random.normal(stddev=0.1, shape=(num_hiddens1, num_hiddens2)))\n",
    "b2 = tf.Variable(tf.zeros(num_hiddens2))\n",
    "W3 = tf.Variable(tf.random.truncated_normal(stddev=0.01, shape=(num_hiddens2, num_outputs)))\n",
    "b3 = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.13.2.2 定义模型\n",
    "drop_prob1, drop_prob2 = 0.2, 0.5\n",
    "\n",
    "def net(X, is_training=False):\n",
    "    X = tf.reshape(X, shape=(-1,num_inputs))\n",
    "    H1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    if is_training:# 只在训练模型时使用丢弃法\n",
    "        H1 = dropout(H1, drop_prob1)  # 在第一层全连接后添加丢弃层\n",
    "    H2 = nn.relu(tf.matmul(H1, W2) + b2)\n",
    "    if is_training:\n",
    "        H2 = dropout(H2, drop_prob2)  # 在第二层全连接后添加丢弃层\n",
    "    return tf.math.softmax(tf.matmul(H2, W3) + b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 3s 86us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 2966s 112us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 33us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 47s 11us/step\n"
     ]
    }
   ],
   "source": [
    "# 我们在对模型评估的时候不应该进行丢弃，所以要修改一下evaluate_accuracy函数\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "batch_size=256\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = tf.cast(x_train, tf.float32) / 255 #在进行矩阵相乘时需要float型，故强制类型转换为float型\n",
    "x_test = tf.cast(x_test,tf.float32) / 255 #在进行矩阵相乘时需要float型，故强制类型转换为float型\n",
    "train_iter = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "test_iter = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for _, (X, y) in enumerate(data_iter):\n",
    "        y = tf.cast(y,dtype=tf.int64)\n",
    "        acc_sum += np.sum(tf.cast(tf.argmax(net(X), axis=1), dtype=tf.int64) == y)\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, trainer=None):\n",
    "    global sample_grads\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_hat = net(X, is_training=True)\n",
    "                l = tf.reduce_sum(loss(y_hat, tf.one_hot(y, depth=10, axis=-1, dtype=tf.float32)))\n",
    "\n",
    "            grads = tape.gradient(l, params)\n",
    "            if trainer is None:\n",
    "\n",
    "                sample_grads = grads\n",
    "                params[0].assign_sub(grads[0] * lr)\n",
    "                params[1].assign_sub(grads[1] * lr)\n",
    "            else:\n",
    "                trainer.apply_gradients(zip(grads, params)) \n",
    "\n",
    "            y = tf.cast(y, dtype=tf.float32)\n",
    "            train_l_sum += l.numpy()\n",
    "            train_acc_sum += tf.reduce_sum(tf.cast(tf.argmax(y_hat, axis=1) == tf.cast(y, dtype=tf.int64), dtype=tf.int64)).numpy()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0353, train acc 0.556, test acc 0.667\n",
      "epoch 2, loss 0.0257, train acc 0.651, test acc 0.677\n",
      "epoch 3, loss 0.0238, train acc 0.666, test acc 0.684\n",
      "epoch 4, loss 0.0225, train acc 0.684, test acc 0.717\n",
      "epoch 5, loss 0.0212, train acc 0.712, test acc 0.738\n"
     ]
    }
   ],
   "source": [
    "# 训练和测试模型\n",
    "\n",
    "num_epochs, lr, batch_size = 5, 0.5, 256\n",
    "loss = tf.losses.CategoricalCrossentropy()\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.6606 - accuracy: 0.7653 - val_loss: 0.4452 - val_accuracy: 0.8406\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4292 - accuracy: 0.8470 - val_loss: 0.3958 - val_accuracy: 0.8574\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3815 - accuracy: 0.8622 - val_loss: 0.3699 - val_accuracy: 0.8643\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3601 - accuracy: 0.8690 - val_loss: 0.3618 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3428 - accuracy: 0.8750 - val_loss: 0.3639 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c690e9ab38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 简洁实现\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(keras.layers.Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=5,batch_size=256,validation_data=(x_test, y_test),\n",
    "                    validation_freq=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
